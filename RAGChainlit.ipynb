{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Nf7jikLZE1R",
        "outputId": "df1fbf04-3544-4fbd-9b38-44312d0f0705"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RAG-Chainlit'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 28 (delta 7), reused 26 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (28/28), 14.49 MiB | 10.80 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dauvannam1804/RAG-Chainlit.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd RAG-Chainlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIj9niNnZVdg",
        "outputId": "fd8f41a0-8f5b-45a1-9e78-3e243de7695f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/RAG-Chainlit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "BCdrXSC1Zb6P",
        "outputId": "212a681d-f3e3-4966-e9ec-b46edf1520b5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/RAG-Chainlit'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qr requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZYzNoOZaICF",
        "outputId": "139d104f-e76b-4587-bddc-13d9340f4c73"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/49.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.6/396.6 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m559.5/559.5 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.8/289.8 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.1/374.1 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.1/249.1 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.3/157.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for literalai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for syncer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# replace this code in src/app.py\n",
        "def get_huggingface_llm(model_name: str = \"lmsys/vicuna-7b-v1.5\", max_new_token: int = 512):\n",
        "    nf4_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16\n",
        "    )\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        quantization_config=nf4_config,\n",
        "        low_cpu_mem_usage=True\n",
        "    )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    model_pipeline = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        max_new_tokens=max_new_token,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "\n",
        "    llm = HuggingFacePipeline(\n",
        "        pipeline=model_pipeline,\n",
        "    )\n",
        "\n",
        "    return llm\n",
        "'''"
      ],
      "metadata": {
        "id": "IAjlATu9j7Fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 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"
      ],
      "metadata": {
        "id": "Fdqzt01Qg9cD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UabAgzMDa9Oo",
        "outputId": "1fce4276-5944-43cc-dff8-7eaa7e1dde80"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok -q"
      ],
      "metadata": {
        "id": "hlCbh8ZmfbPW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok"
      ],
      "metadata": {
        "id": "Jhf07mtPgYE6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2m0bR9SGXpKNHTMUZ7vNZyNSS2h_4Juh6dsjS7gTKVzqgQwVD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiqjULjafdJG",
        "outputId": "0be7c0e5-254a-4e10-dc96-fc9e8b50f419"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "public_url = ngrok.connect(8000).public_url"
      ],
      "metadata": {
        "id": "TxB-rp1Dfghh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYuFax6Xh1Px",
        "outputId": "1243a8dd-5e5b-4101-b013-6207576e3d77"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://53a0-34-87-22-52.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chainlit run /content/RAG-Chainlit/src/app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvy8ZRYBhSwn",
        "outputId": "435ee30c-1dd4-47fa-e305-d12d4a10f8d4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-13 08:48:37 - Created default config file at /content/RAG-Chainlit/.chainlit/config.toml\n",
            "2024-09-13 08:48:37 - Created default translation directory at /content/RAG-Chainlit/.chainlit/translations\n",
            "2024-09-13 08:48:37 - Created default translation file at /content/RAG-Chainlit/.chainlit/translations/en-US.json\n",
            "2024-09-13 08:48:37 - Created default translation file at /content/RAG-Chainlit/.chainlit/translations/zh-CN.json\n",
            "2024-09-13 08:48:44.158088: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-13 08:48:44.178492: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-13 08:48:44.184710: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-13 08:48:44.200086: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-09-13 08:48:45.221911: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-09-13 08:48:49 - Use pytorch device_name: cuda\n",
            "2024-09-13 08:48:49 - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
            "modules.json: 100% 349/349 [00:00<00:00, 2.26MB/s]\n",
            "config_sentence_transformers.json: 100% 116/116 [00:00<00:00, 617kB/s]\n",
            "README.md: 100% 10.6k/10.6k [00:00<00:00, 49.9MB/s]\n",
            "sentence_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 322kB/s]\n",
            "config.json: 100% 571/571 [00:00<00:00, 3.30MB/s]\n",
            "model.safetensors: 100% 438M/438M [00:01<00:00, 319MB/s]\n",
            "tokenizer_config.json: 100% 363/363 [00:00<00:00, 2.23MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 77.9MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 2.17MB/s]\n",
            "special_tokens_map.json: 100% 239/239 [00:00<00:00, 1.42MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "1_Pooling/config.json: 100% 190/190 [00:00<00:00, 1.10MB/s]\n",
            "config.json: 100% 615/615 [00:00<00:00, 3.45MB/s]\n",
            "pytorch_model.bin.index.json: 100% 26.8k/26.8k [00:00<00:00, 74.5MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "pytorch_model-00001-of-00002.bin:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   0% 41.9M/9.98G [00:00<00:28, 347MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 94.4M/9.98G [00:00<00:25, 394MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 136M/9.98G [00:00<00:27, 359MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 178M/9.98G [00:00<00:28, 339MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 220M/9.98G [00:00<00:30, 316MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 262M/9.98G [00:00<00:30, 316MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 304M/9.98G [00:00<00:30, 318MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 346M/9.98G [00:01<00:29, 331MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 388M/9.98G [00:01<00:28, 335MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 430M/9.98G [00:01<00:27, 344MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 472M/9.98G [00:01<00:27, 347MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 514M/9.98G [00:01<00:26, 350MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 566M/9.98G [00:01<00:32, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 598M/9.98G [00:01<00:32, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 629M/9.98G [00:01<00:32, 289MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 661M/9.98G [00:02<00:34, 269MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 692M/9.98G [00:02<00:34, 273MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 724M/9.98G [00:02<00:35, 259MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 755M/9.98G [00:02<00:33, 273MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 797M/9.98G [00:02<00:31, 287MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 828M/9.98G [00:02<00:37, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 860M/9.98G [00:02<00:38, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 891M/9.98G [00:03<00:38, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 923M/9.98G [00:03<00:37, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 954M/9.98G [00:03<00:37, 244MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 986M/9.98G [00:03<00:38, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.03G/9.98G [00:03<00:34, 260MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.06G/9.98G [00:03<00:35, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.09G/9.98G [00:03<00:35, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.12G/9.98G [00:03<00:36, 244MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.15G/9.98G [00:04<00:36, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.18G/9.98G [00:05<02:40, 54.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.21G/9.98G [00:06<02:42, 53.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.26G/9.98G [00:06<01:40, 87.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.30G/9.98G [00:06<01:14, 116MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.33G/9.98G [00:06<01:02, 138MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.37G/9.98G [00:06<00:49, 174MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.41G/9.98G [00:06<00:43, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.45G/9.98G [00:06<00:38, 221MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.48G/9.98G [00:06<00:36, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.52G/9.98G [00:07<00:32, 261MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.56G/9.98G [00:07<00:29, 289MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.60G/9.98G [00:07<00:27, 303MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.65G/9.98G [00:07<00:28, 297MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.69G/9.98G [00:07<00:26, 316MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.73G/9.98G [00:07<00:26, 310MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.77G/9.98G [00:07<00:28, 292MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.80G/9.98G [00:08<00:28, 288MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.84G/9.98G [00:08<00:28, 290MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.87G/9.98G [00:08<00:30, 266MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.90G/9.98G [00:08<00:31, 259MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.93G/9.98G [00:08<00:31, 259MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.96G/9.98G [00:08<00:32, 249MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.99G/9.98G [00:08<00:31, 251MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.02G/9.98G [00:08<00:31, 253MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.06G/9.98G [00:09<00:32, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.09G/9.98G [00:09<00:31, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.12G/9.98G [00:09<00:31, 249MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.15G/9.98G [00:09<00:33, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.18G/9.98G [00:09<00:33, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.21G/9.98G [00:09<00:33, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.24G/9.98G [00:09<00:34, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.28G/9.98G [00:10<00:34, 220MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.31G/9.98G [00:10<00:35, 215MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.34G/9.98G [00:10<00:34, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.37G/9.98G [00:10<00:33, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.40G/9.98G [00:10<00:32, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.43G/9.98G [00:10<00:32, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.46G/9.98G [00:10<00:32, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.50G/9.98G [00:10<00:32, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.53G/9.98G [00:11<00:31, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.56G/9.98G [00:11<00:31, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.59G/9.98G [00:11<00:32, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.62G/9.98G [00:11<00:31, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.65G/9.98G [00:11<00:31, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.68G/9.98G [00:11<00:31, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.72G/9.98G [00:11<00:31, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.75G/9.98G [00:12<00:32, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.78G/9.98G [00:12<00:31, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.81G/9.98G [00:12<00:31, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.84G/9.98G [00:12<00:31, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.87G/9.98G [00:12<00:31, 226MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.90G/9.98G [00:12<00:30, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.94G/9.98G [00:12<00:31, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.97G/9.98G [00:13<00:30, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.00G/9.98G [00:13<00:32, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.03G/9.98G [00:13<00:29, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.06G/9.98G [00:13<00:29, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.09G/9.98G [00:13<00:30, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.12G/9.98G [00:13<00:31, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.16G/9.98G [00:13<00:30, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.19G/9.98G [00:14<00:29, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.22G/9.98G [00:14<00:27, 249MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.26G/9.98G [00:14<00:24, 273MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.30G/9.98G [00:14<00:22, 295MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.34G/9.98G [00:14<00:22, 296MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.38G/9.98G [00:14<00:22, 293MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.42G/9.98G [00:14<00:21, 312MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.45G/9.98G [00:14<00:21, 300MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.48G/9.98G [00:14<00:21, 296MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.52G/9.98G [00:15<00:21, 304MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.57G/9.98G [00:15<00:20, 311MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.61G/9.98G [00:15<00:19, 330MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.66G/9.98G [00:15<00:17, 355MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.70G/9.98G [00:15<00:24, 259MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.73G/9.98G [00:15<00:23, 267MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.76G/9.98G [00:15<00:22, 270MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.80G/9.98G [00:16<00:22, 276MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.84G/9.98G [00:16<00:21, 288MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.88G/9.98G [00:16<00:20, 302MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.91G/9.98G [00:16<00:22, 274MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.94G/9.98G [00:16<00:21, 277MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.97G/9.98G [00:16<00:23, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.01G/9.98G [00:16<00:22, 267MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.04G/9.98G [00:16<00:22, 269MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.07G/9.98G [00:17<00:23, 251MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.10G/9.98G [00:17<00:25, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.13G/9.98G [00:17<00:24, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.17G/9.98G [00:17<00:22, 253MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.20G/9.98G [00:17<00:25, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.25G/9.98G [00:17<00:22, 253MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.29G/9.98G [00:17<00:21, 271MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.32G/9.98G [00:18<00:22, 257MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.36G/9.98G [00:18<00:21, 259MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.39G/9.98G [00:18<00:21, 263MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.42G/9.98G [00:20<02:08, 43.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.48G/9.98G [00:20<01:21, 67.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.52G/9.98G [00:20<01:00, 89.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.55G/9.98G [00:21<00:50, 107MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.58G/9.98G [00:21<00:42, 128MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.61G/9.98G [00:21<00:35, 152MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.65G/9.98G [00:21<00:30, 175MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.69G/9.98G [00:21<00:24, 212MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.73G/9.98G [00:21<00:21, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.77G/9.98G [00:21<00:21, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.80G/9.98G [00:21<00:21, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.83G/9.98G [00:22<00:21, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.87G/9.98G [00:22<00:23, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.90G/9.98G [00:26<03:37, 23.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.95G/9.98G [00:26<02:13, 37.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 5.00G/9.98G [00:26<01:28, 56.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 5.03G/9.98G [00:27<01:12, 68.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.06G/9.98G [00:27<00:58, 84.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.10G/9.98G [00:27<00:51, 95.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.14G/9.98G [00:27<00:38, 127MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.18G/9.98G [00:27<00:30, 159MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.22G/9.98G [00:27<00:24, 191MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.25G/9.98G [00:27<00:22, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.28G/9.98G [00:27<00:20, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.32G/9.98G [00:28<00:19, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.35G/9.98G [00:28<00:19, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.38G/9.98G [00:28<00:18, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.41G/9.98G [00:28<00:18, 253MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.44G/9.98G [00:28<00:18, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.47G/9.98G [00:28<00:17, 260MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.51G/9.98G [00:28<00:17, 250MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.54G/9.98G [00:28<00:17, 250MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.57G/9.98G [00:29<00:18, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.60G/9.98G [00:29<00:21, 199MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.63G/9.98G [00:35<04:13, 17.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.68G/9.98G [00:35<02:30, 28.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.71G/9.98G [00:35<01:53, 37.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.75G/9.98G [00:35<01:26, 48.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.78G/9.98G [00:35<01:06, 63.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.81G/9.98G [00:35<00:51, 80.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.85G/9.98G [00:35<00:37, 111MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.88G/9.98G [00:35<00:30, 133MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.91G/9.98G [00:40<03:27, 19.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.93G/9.98G [00:41<02:49, 23.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.97G/9.98G [00:41<01:59, 33.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 6.01G/9.98G [00:41<01:17, 51.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.05G/9.98G [00:41<00:54, 72.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.08G/9.98G [00:41<00:42, 91.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.11G/9.98G [00:41<00:34, 114MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.14G/9.98G [00:41<00:31, 122MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.18G/9.98G [00:42<00:38, 99.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.20G/9.98G [00:47<03:44, 16.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.25G/9.98G [00:47<02:08, 29.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.30G/9.98G [00:47<01:21, 45.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.34G/9.98G [00:47<00:59, 60.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.38G/9.98G [00:48<01:02, 57.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.41G/9.98G [00:52<02:46, 21.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.43G/9.98G [00:53<02:40, 22.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.47G/9.98G [00:53<01:45, 33.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.51G/9.98G [00:53<01:11, 48.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.54G/9.98G [00:53<00:55, 61.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.57G/9.98G [00:53<00:44, 77.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.62G/9.98G [00:53<00:31, 106MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.65G/9.98G [00:53<00:26, 128MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.68G/9.98G [00:54<00:22, 146MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.71G/9.98G [00:54<00:19, 168MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.74G/9.98G [00:54<00:18, 171MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.77G/9.98G [00:54<00:16, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.82G/9.98G [00:54<00:14, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.85G/9.98G [00:54<00:14, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.88G/9.98G [00:54<00:13, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.92G/9.98G [00:55<00:11, 256MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.95G/9.98G [00:55<00:12, 248MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.98G/9.98G [00:55<00:12, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 7.03G/9.98G [00:55<00:10, 269MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.06G/9.98G [00:55<00:11, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.09G/9.98G [00:55<00:12, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.12G/9.98G [00:55<00:11, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.16G/9.98G [00:56<00:10, 277MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.19G/9.98G [00:56<00:11, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.22G/9.98G [00:56<00:11, 240MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.27G/9.98G [00:56<00:10, 266MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.30G/9.98G [00:56<00:10, 249MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.33G/9.98G [00:56<00:10, 248MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.36G/9.98G [00:56<00:10, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.39G/9.98G [00:57<00:11, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.43G/9.98G [00:57<00:10, 251MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.47G/9.98G [00:57<00:09, 261MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.50G/9.98G [00:57<00:10, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.53G/9.98G [00:57<00:09, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.57G/9.98G [00:57<00:08, 279MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.60G/9.98G [00:57<00:09, 245MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.63G/9.98G [00:57<00:09, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.67G/9.98G [00:58<00:09, 251MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.70G/9.98G [00:58<00:08, 260MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.73G/9.98G [00:58<00:09, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.77G/9.98G [00:58<00:08, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.80G/9.98G [00:58<00:08, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.84G/9.98G [00:58<00:08, 266MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.87G/9.98G [00:58<00:07, 263MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.91G/9.98G [00:59<00:12, 169MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.93G/9.98G [01:09<00:12, 169MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.94G/9.98G [01:10<03:38, 9.33MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.95G/9.98G [01:20<06:52, 4.92MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.96G/9.98G [01:36<06:49, 4.92MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.97G/9.98G [01:47<16:20, 2.05MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.99G/9.98G [01:48<11:54, 2.78MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 8.01G/9.98G [01:48<08:35, 3.81MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.03G/9.98G [01:48<06:11, 5.23MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.05G/9.98G [01:48<04:25, 7.25MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.08G/9.98G [01:48<02:44, 11.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.12G/9.98G [01:48<01:47, 17.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.15G/9.98G [01:48<01:12, 25.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.18G/9.98G [01:49<00:51, 35.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.21G/9.98G [01:49<00:36, 48.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.25G/9.98G [01:49<00:24, 69.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.28G/9.98G [01:49<00:19, 87.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.32G/9.98G [01:49<00:15, 108MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.35G/9.98G [01:49<00:12, 128MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.38G/9.98G [01:49<00:10, 152MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.41G/9.98G [01:49<00:09, 170MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.44G/9.98G [01:50<00:07, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.47G/9.98G [01:50<00:06, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.50G/9.98G [01:50<00:07, 199MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.54G/9.98G [01:50<00:07, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.57G/9.98G [01:50<00:06, 202MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.60G/9.98G [01:50<00:06, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.63G/9.98G [01:50<00:06, 217MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.66G/9.98G [01:51<00:05, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.69G/9.98G [01:51<00:05, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.72G/9.98G [01:51<00:04, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.76G/9.98G [01:51<00:04, 267MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.80G/9.98G [01:51<00:04, 268MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.84G/9.98G [01:51<00:03, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.88G/9.98G [01:51<00:03, 288MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.91G/9.98G [01:51<00:03, 277MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.94G/9.98G [01:52<00:03, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.98G/9.98G [01:52<00:04, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 9.01G/9.98G [01:52<00:03, 248MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.06G/9.98G [01:52<00:03, 264MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.09G/9.98G [01:52<00:03, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.12G/9.98G [01:52<00:03, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.16G/9.98G [01:53<00:03, 245MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.21G/9.98G [01:53<00:02, 277MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.24G/9.98G [01:53<00:02, 267MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.27G/9.98G [01:53<00:02, 263MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.30G/9.98G [01:53<00:02, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.33G/9.98G [01:53<00:02, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.37G/9.98G [01:53<00:02, 271MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.41G/9.98G [01:53<00:02, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.45G/9.98G [01:54<00:01, 275MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.48G/9.98G [01:54<00:01, 284MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.51G/9.98G [01:54<00:01, 270MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.54G/9.98G [01:54<00:01, 256MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.57G/9.98G [01:54<00:01, 262MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.60G/9.98G [01:54<00:01, 260MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.64G/9.98G [01:54<00:01, 271MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.67G/9.98G [01:54<00:01, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.70G/9.98G [01:55<00:01, 226MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.74G/9.98G [01:55<00:00, 261MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.77G/9.98G [01:55<00:00, 258MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.80G/9.98G [01:55<00:00, 251MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.84G/9.98G [01:55<00:00, 256MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.87G/9.98G [01:55<00:00, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.90G/9.98G [01:56<00:00, 87.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.92G/9.98G [01:58<00:01, 44.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.95G/9.98G [01:58<00:00, 56.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.98G/9.98G [01:58<00:00, 84.0MB/s]\n",
            "Downloading shards:  50% 1/2 [01:58<01:58, 118.95s/it]\n",
            "pytorch_model-00002-of-00002.bin:   0% 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   1% 41.9M/3.50G [00:00<00:09, 358MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   2% 83.9M/3.50G [00:00<00:09, 369MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   4% 126M/3.50G [00:00<00:10, 324MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   5% 168M/3.50G [00:00<00:10, 303MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   6% 210M/3.50G [00:00<00:10, 318MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   7% 252M/3.50G [00:00<00:11, 278MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   8% 283M/3.50G [00:00<00:12, 268MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   9% 315M/3.50G [00:01<00:13, 237MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  10% 346M/3.50G [00:01<00:19, 163MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  10% 367M/3.50G [00:06<02:43, 19.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  12% 419M/3.50G [00:06<01:34, 32.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  13% 461M/3.50G [00:06<01:05, 46.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  14% 493M/3.50G [00:06<00:50, 59.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  15% 535M/3.50G [00:06<00:36, 81.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  16% 566M/3.50G [00:06<00:29, 99.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  17% 598M/3.50G [00:06<00:23, 121MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  18% 629M/3.50G [00:06<00:19, 146MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  19% 661M/3.50G [00:14<03:19, 14.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  20% 703M/3.50G [00:14<02:10, 21.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  21% 734M/3.50G [00:14<01:36, 28.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  22% 776M/3.50G [00:14<01:04, 41.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  23% 818M/3.50G [00:14<00:46, 58.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  24% 849M/3.50G [00:14<00:38, 69.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  25% 881M/3.50G [00:15<00:43, 59.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  26% 902M/3.50G [00:18<01:41, 25.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  27% 954M/3.50G [00:18<01:00, 42.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  28% 986M/3.50G [00:18<00:46, 54.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  29% 1.02G/3.50G [00:18<00:35, 69.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  30% 1.05G/3.50G [00:18<00:27, 88.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  31% 1.08G/3.50G [00:18<00:21, 110MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  32% 1.11G/3.50G [00:18<00:17, 135MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  33% 1.15G/3.50G [00:19<00:13, 170MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  34% 1.18G/3.50G [00:19<00:12, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  35% 1.22G/3.50G [00:19<00:11, 198MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  36% 1.26G/3.50G [00:19<00:10, 219MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  37% 1.29G/3.50G [00:19<00:09, 227MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  38% 1.32G/3.50G [00:19<00:09, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  39% 1.35G/3.50G [00:19<00:09, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  40% 1.38G/3.50G [00:20<00:08, 243MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  40% 1.42G/3.50G [00:20<00:08, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  41% 1.45G/3.50G [00:20<00:09, 210MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  42% 1.48G/3.50G [00:20<00:08, 229MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  43% 1.51G/3.50G [00:24<01:20, 24.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  45% 1.56G/3.50G [00:24<00:47, 40.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  46% 1.61G/3.50G [00:24<00:30, 61.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  47% 1.65G/3.50G [00:24<00:24, 74.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  48% 1.68G/3.50G [00:24<00:20, 91.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  49% 1.72G/3.50G [00:25<00:14, 120MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  50% 1.76G/3.50G [00:25<00:11, 149MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  51% 1.79G/3.50G [00:25<00:10, 171MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  52% 1.84G/3.50G [00:25<00:08, 204MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  54% 1.88G/3.50G [00:25<00:07, 227MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  55% 1.92G/3.50G [00:25<00:06, 252MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  56% 1.96G/3.50G [00:25<00:05, 270MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  57% 2.00G/3.50G [00:25<00:05, 288MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  58% 2.04G/3.50G [00:26<00:05, 279MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  59% 2.08G/3.50G [00:26<00:05, 255MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  61% 2.12G/3.50G [00:26<00:05, 261MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  61% 2.15G/3.50G [00:26<00:05, 265MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  62% 2.18G/3.50G [00:26<00:05, 235MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  63% 2.21G/3.50G [00:26<00:05, 237MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  64% 2.24G/3.50G [00:26<00:05, 236MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  65% 2.28G/3.50G [00:27<00:05, 242MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  66% 2.31G/3.50G [00:27<00:04, 247MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  67% 2.35G/3.50G [00:27<00:04, 269MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  68% 2.38G/3.50G [00:27<00:04, 242MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  69% 2.41G/3.50G [00:27<00:05, 204MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  70% 2.44G/3.50G [00:27<00:04, 218MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  71% 2.47G/3.50G [00:27<00:04, 210MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  72% 2.51G/3.50G [00:28<00:04, 212MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  72% 2.54G/3.50G [00:28<00:04, 216MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  73% 2.57G/3.50G [00:28<00:03, 234MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  74% 2.60G/3.50G [00:28<00:03, 229MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  75% 2.63G/3.50G [00:28<00:03, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  76% 2.66G/3.50G [00:28<00:03, 233MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  77% 2.69G/3.50G [00:28<00:03, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  78% 2.74G/3.50G [00:29<00:02, 260MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  79% 2.77G/3.50G [00:29<00:03, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  80% 2.80G/3.50G [00:29<00:02, 240MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  81% 2.83G/3.50G [00:29<00:02, 251MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  82% 2.87G/3.50G [00:29<00:02, 273MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  83% 2.90G/3.50G [00:29<00:02, 266MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  84% 2.94G/3.50G [00:29<00:02, 259MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  85% 2.97G/3.50G [00:30<00:02, 218MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  86% 3.00G/3.50G [00:30<00:03, 164MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  86% 3.02G/3.50G [00:34<00:23, 20.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  88% 3.07G/3.50G [00:34<00:12, 34.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  89% 3.12G/3.50G [00:34<00:06, 53.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  90% 3.16G/3.50G [00:34<00:05, 67.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  91% 3.19G/3.50G [00:35<00:03, 82.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  92% 3.22G/3.50G [00:35<00:02, 103MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  93% 3.25G/3.50G [00:35<00:02, 125MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  94% 3.29G/3.50G [00:35<00:01, 157MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  95% 3.33G/3.50G [00:35<00:00, 191MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  96% 3.37G/3.50G [00:35<00:00, 206MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  97% 3.40G/3.50G [00:35<00:00, 217MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  98% 3.43G/3.50G [00:35<00:00, 225MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  99% 3.46G/3.50G [00:36<00:00, 223MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin: 100% 3.50G/3.50G [00:36<00:00, 96.5MB/s]\n",
            "Downloading shards: 100% 2/2 [02:35<00:00, 77.75s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:59<00:00, 29.64s/it]\n",
            "generation_config.json: 100% 162/162 [00:00<00:00, 812kB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "tokenizer_config.json: 100% 749/749 [00:00<00:00, 4.92MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 203MB/s]\n",
            "special_tokens_map.json: 100% 438/438 [00:00<00:00, 2.96MB/s]\n",
            "2024-09-13 08:52:39 - Created default chainlit markdown file at /content/RAG-Chainlit/chainlit.md\n",
            "2024-09-13 08:52:39 - Your app is available at http://localhost:8000\n",
            "2024-09-13 08:53:02 - Translation file for vi not found. Using default translation en-US.\n",
            "2024-09-13 08:53:03 - Translated markdown file for vi not found. Defaulting to chainlit.md.\n",
            "2024-09-13 08:53:21 - Translation file for vi not found. Using default translation en-US.\n",
            "2024-09-13 08:53:23 - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
            "2024-09-13 08:53:33 - Translation file for vi not found. Using default translation en-US.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "2024-09-13 08:53:59 - Translation file for vi not found. Using default translation en-US.\n",
            "2024-09-13 08:54:05 - Translation file for vi not found. Using default translation en-US.\n",
            "2024-09-13 08:54:22 - Translation file for vi not found. Using default translation en-US.\n",
            "2024-09-13 08:54:37 - Translation file for vi not found. Using default translation en-US.\n",
            "2024-09-13 08:54:51 - Translation file for vi not found. Using default translation en-US.\n",
            "2024-09-13 08:54:59 - Translation file for vi not found. Using default translation en-US.\n"
          ]
        }
      ]
    }
  ]
}